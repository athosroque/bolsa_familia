# ğŸ“Š Portal da TransparÃªncia - Data Pipeline & Analytics

## VisÃ£o Geral do Projeto

Este projeto implementa um **pipeline de dados (ETL/ELT) robusto e escalÃ¡vel** focado na extraÃ§Ã£o, armazenamento e anÃ¡lise de dados do **Bolsa FamÃ­lia** e outros programas sociais brasileiros. A fonte primÃ¡ria dos dados Ã© a API do Portal da TransparÃªncia do Governo Federal. O diferencial deste projeto reside na sua arquitetura local baseada em Docker, na modelagem dimensional para anÃ¡lises eficientes e na integraÃ§Ã£o com **Agentes MCP (Model Context Protocol)**, permitindo que Large Language Models (LLMs) interajam diretamente com os dados.

O objetivo Ã© fornecer uma soluÃ§Ã£o completa para a ingestÃ£o e anÃ¡lise de dados governamentais, facilitando a obtenÃ§Ã£o de insights e a tomada de decisÃµes baseada em dados.

## ğŸ—ï¸ Arquitetura e Fluxo de Dados

O sistema Ã© projetado para rodar inteiramente em um ambiente local containerizado com Docker e segue a arquitetura **ELT (Extract, Load, Transform)**, otimizada para anÃ¡lise de dados. A modelagem dimensional utiliza um **Star Schema** para garantir consultas rÃ¡pidas e eficientes.

### Componentes Principais:

1.  **IngestÃ£o (Extract)**:
    *   Scripts Python (`src/etl/`) sÃ£o responsÃ¡veis por baixar dados da API do Portal da TransparÃªncia.
    *   Gerencia automaticamente a paginaÃ§Ã£o, limites de taxa (rate limits) da API e autenticaÃ§Ã£o.

2.  **Armazenamento (Load)**:
    *   Os dados brutos extraÃ­dos sÃ£o armazenados em formato **JSONB** na tabela `raw_bolsa_familia` em um banco de dados **PostgreSQL 16**.
    *   Esta abordagem permite flexibilidade para esquemas semi-estruturados e facilita futuras transformaÃ§Ãµes.

3.  **TransformaÃ§Ã£o (Transform)**:
    *   ApÃ³s o carregamento, os dados brutos sÃ£o processados e transformados em um formato otimizado para anÃ¡lise.
    *   SÃ£o criadas tabelas dimensionais para estruturar os dados:
        *   `fact_pagamentos_municipio` (Tabela Fato: ContÃ©m as mÃ©tricas e chaves estrangeiras para as dimensÃµes).
        *   `dim_municipio` (Tabela DimensÃ£o: Detalhes sobre os municÃ­pios).
        *   `dim_programa` (Tabela DimensÃ£o: Detalhes sobre os programas sociais).

## ğŸ¤– Agentes MCP (Model Context Protocol)

Uma caracterÃ­stica inovadora deste projeto Ã© a inclusÃ£o de servidores **MCP (Model Context Protocol)**, que permitem a interaÃ§Ã£o de LLMs (como Claude ou Gemini) com os dados e a API de forma segura e controlada. Isso abre portas para anÃ¡lises conversacionais e automaÃ§Ã£o inteligente.

-   **`pg-aiguide`**: Este agente permite que LLMs consultem o banco de dados PostgreSQL. Ele pode listar tabelas, descrever esquemas e executar consultas SQL de forma controlada, facilitando a exploraÃ§Ã£o de dados por meio de linguagem natural.
-   **`portal-safe`**: Um cliente de API seguro que permite que LLMs realizem consultas em tempo real Ã  API do Portal da TransparÃªncia, garantindo que as interaÃ§Ãµes com a API externa sejam gerenciadas de forma eficiente e segura.

## ğŸ› ï¸ Stack TecnolÃ³gica

-   **Linguagem**: `Python`
-   **OrquestraÃ§Ã£o**: `Docker` & `Docker Compose`
-   **Banco de Dados**: `PostgreSQL 16`
-   **Processamento de Dados**: `Pandas`
-   **IntegraÃ§Ã£o LLM**: `Model Context Protocol (MCP)`
-   **Ferramentas**: `API do Portal da TransparÃªncia`

## ğŸš€ Como Rodar o Projeto (Guia de InÃ­cio RÃ¡pido)

Para configurar e executar o pipeline de dados localmente, siga as instruÃ§Ãµes abaixo:

### 1. PrÃ©-requisitos

Certifique-se de ter os seguintes softwares instalados:

-   **Docker**
-   **Docker Compose**

AlÃ©m disso, vocÃª precisarÃ¡ de uma chave de API do Portal da TransparÃªncia. Crie um arquivo `.env` na raiz do projeto com o seguinte conteÃºdo:

```dotenv
API_KEY=SUA_CHAVE_DE_API_AQUI
```

### 2. Iniciar os ServiÃ§os

Execute o script de configuraÃ§Ã£o para construir as imagens Docker e iniciar os serviÃ§os:

```bash
./setup.sh
```

### 3. Executar a Carga de Dados (ETL)

#### Para baixar dados de um mÃªs especÃ­fico:

```bash
sudo docker compose exec etl python src/etl/extract_bolsa_familia.py --month YYYYMM
# Exemplo: sudo docker compose exec etl python src/etl/extract_bolsa_familia.py --month 202401
```

#### Para baixar dados de um ano inteiro (modo Batch):

```bash
sudo docker compose exec -d etl python src/etl/extract_bolsa_familia.py --year YYYY
# Exemplo: sudo docker compose exec -d etl python src/etl/extract_bolsa_familia.py --year 2024
```

### 4. AnÃ¡lise ExploratÃ³ria de Dados (com Pandas)

Para interagir com os dados carregados em um shell Python com Pandas, execute:

```bash
sudo docker compose exec -it -e PYTHONPATH=/app etl python src/analysis/repl_session.py
```

## ğŸ“‚ Estrutura de Arquivos

```text
â”œâ”€â”€ .env                     # VariÃ¡veis de ambiente (API_KEY)
â”œâ”€â”€ docker-compose.yml       # DefiniÃ§Ã£o dos serviÃ§os Docker
â”œâ”€â”€ fix_initialization.sh    # Script para corrigir inicializaÃ§Ã£o (se necessÃ¡rio)
â”œâ”€â”€ host.json                # ConfiguraÃ§Ã£o do Azure Function Host (se aplicÃ¡vel)
â”œâ”€â”€ postgres_mcp.py          # Servidor MCP para PostgreSQL
â”œâ”€â”€ portal_safe_server.py    # Servidor MCP para a API do Portal da TransparÃªncia
â”œâ”€â”€ requirements.txt         # DependÃªncias Python
â”œâ”€â”€ sample_response.json     # Exemplo de resposta da API
â”œâ”€â”€ setup.sh                 # Script de configuraÃ§Ã£o e inicializaÃ§Ã£o
â”œâ”€â”€ tests/                   # Testes unitÃ¡rios e de integraÃ§Ã£o
â”‚   â”œâ”€â”€ inspect_api.py
â”‚   â””â”€â”€ verify_setup.py
â””â”€â”€ src/                     # CÃ³digo fonte principal
    â”œâ”€â”€ analysis/            # Scripts para anÃ¡lise de dados
    â”‚   â”œâ”€â”€ repl_session.py  # Shell interativo com Pandas
    â”‚   â””â”€â”€ verify_pandas.py
    â”œâ”€â”€ db/                  # ConexÃ£o e esquema do banco de dados
    â”‚   â””â”€â”€ connection.py
    â””â”€â”€ etl/                 # Scripts de ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga
        â”œâ”€â”€ __init__.py
        â””â”€â”€ extract_bolsa_familia.py
```

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues para sugestÃµes ou melhorias, ou enviar Pull Requests.

---

Desenvolvido por **Athos Roque Barros**

[LinkedIn](https://www.linkedin.com/in/athos-roque-barros-622038152/)
[GitHub](https://github.com/athosroque)
